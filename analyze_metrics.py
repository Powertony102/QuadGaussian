import pandas as pd
import numpy as np
import os
import argparse
from pathlib import Path
from collections import defaultdict

# ä» full_eval.py å¯¼å…¥åœºæ™¯å®šä¹‰
mipnerf360_outdoor_scenes = ["bicycle", "flowers", "garden", "stump", "treehill"]
mipnerf360_indoor_scenes = ["room", "counter", "kitchen", "bonsai"]
tanks_and_temples_scenes = ["truck", "train"]
deep_blending_scenes = ["drjohnson", "playroom"]

def get_dataset_name(scene_name):
    """æ ¹æ®åœºæ™¯åç§°è¿”å›æ•°æ®é›†åç§°"""
    if scene_name in mipnerf360_outdoor_scenes:
        return "MipNeRF360-Outdoor"
    elif scene_name in mipnerf360_indoor_scenes:
        return "MipNeRF360-Indoor"
    elif scene_name in tanks_and_temples_scenes:
        return "Tanks&Temples"
    elif scene_name in deep_blending_scenes:
        return "DeepBlending"
    else:
        return "Unknown"

def load_metrics_from_path(base_path, iteration=30000, split="test"):
    """
    ä»æŒ‡å®šè·¯å¾„åŠ è½½æ‰€æœ‰åœºæ™¯çš„æŒ‡æ ‡æ•°æ®
    
    Args:
        base_path: åŸºç¡€è·¯å¾„ï¼Œå¦‚ /home/jovyan/work/gs_07/QuadGaussian/eval
        iteration: è¿­ä»£æ¬¡æ•°
        split: æ•°æ®é›†åˆ†å‰²ï¼ˆtrain/testï¼‰
    
    Returns:
        dict: åŒ…å«æ‰€æœ‰åœºæ™¯æŒ‡æ ‡æ•°æ®çš„å­—å…¸
    """
    metrics_data = {}
    base_path = Path(base_path)
    
    # è·å–æ‰€æœ‰åœºæ™¯
    all_scenes = []
    all_scenes.extend(mipnerf360_outdoor_scenes)
    all_scenes.extend(mipnerf360_indoor_scenes)
    all_scenes.extend(tanks_and_temples_scenes)
    all_scenes.extend(deep_blending_scenes)
    
    for scene in all_scenes:
        metrics_file = base_path / scene / split / f"ours_{iteration}" / "metrics.csv"
        
        if metrics_file.exists():
            try:
                df = pd.read_csv(metrics_file)
                metrics_data[scene] = df.iloc[0].to_dict()  # å–ç¬¬ä¸€è¡Œæ•°æ®
                print(f"âœ… åŠ è½½ {scene}: {metrics_file}")
            except Exception as e:
                print(f"âŒ åŠ è½½ {scene} å¤±è´¥: {e}")
        else:
            print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {metrics_file}")
    
    return metrics_data

def calculate_dataset_averages(metrics_data):
    """
    è®¡ç®—æ¯ä¸ªæ•°æ®é›†çš„å¹³å‡å€¼
    
    Args:
        metrics_data: åŒ…å«æ‰€æœ‰åœºæ™¯æŒ‡æ ‡æ•°æ®çš„å­—å…¸
    
    Returns:
        dict: æ¯ä¸ªæ•°æ®é›†çš„å¹³å‡å€¼
    """
    dataset_metrics = defaultdict(list)
    
    # æŒ‰æ•°æ®é›†åˆ†ç»„
    for scene, metrics in metrics_data.items():
        dataset_name = get_dataset_name(scene)
        dataset_metrics[dataset_name].append(metrics)
    
    # è®¡ç®—æ¯ä¸ªæ•°æ®é›†çš„å¹³å‡å€¼
    dataset_averages = {}
    for dataset_name, metrics_list in dataset_metrics.items():
        if metrics_list:
            # è½¬æ¢ä¸ºDataFrameè¿›è¡Œè®¡ç®—
            df = pd.DataFrame(metrics_list)
            averages = df.mean().to_dict()
            dataset_averages[dataset_name] = averages
            print(f"ğŸ“Š {dataset_name}: {len(metrics_list)} ä¸ªåœºæ™¯")
    
    # è®¡ç®—MipNeRF360æ€»ä½“å¹³å‡å€¼ï¼ˆIndoor + Outdoorï¼‰
    mipnerf360_indoor_metrics = dataset_metrics.get("MipNeRF360-Indoor", [])
    mipnerf360_outdoor_metrics = dataset_metrics.get("MipNeRF360-Outdoor", [])
    
    if mipnerf360_indoor_metrics or mipnerf360_outdoor_metrics:
        all_mipnerf360_metrics = mipnerf360_indoor_metrics + mipnerf360_outdoor_metrics
        if all_mipnerf360_metrics:
            df = pd.DataFrame(all_mipnerf360_metrics)
            averages = df.mean().to_dict()
            dataset_averages["MipNeRF360-All"] = averages
            print(f"ğŸ“Š MipNeRF360-All: {len(all_mipnerf360_metrics)} ä¸ªåœºæ™¯")
    
    return dataset_averages

def print_results(metrics_data, dataset_averages, output_format="table"):
    """
    æ‰“å°ç»“æœ
    
    Args:
        metrics_data: åŸå§‹æŒ‡æ ‡æ•°æ®
        dataset_averages: æ•°æ®é›†å¹³å‡å€¼
        output_format: è¾“å‡ºæ ¼å¼ (table/csv)
    """
    if output_format == "table":
        print("\n" + "="*80)
        print("ğŸ“ˆ æ•°æ®é›†å¹³å‡å€¼ç»Ÿè®¡")
        print("="*80)
        
        # å®šä¹‰æ•°æ®é›†æ˜¾ç¤ºé¡ºåº
        dataset_order = [
            "MipNeRF360-Outdoor",
            "MipNeRF360-Indoor", 
            "MipNeRF360-All",
            "Tanks&Temples",
            "DeepBlending"
        ]
        
        # æŒ‰é¡ºåºæ‰“å°æ¯ä¸ªæ•°æ®é›†çš„å¹³å‡å€¼
        for dataset_name in dataset_order:
            if dataset_name in dataset_averages:
                averages = dataset_averages[dataset_name]
                print(f"\nğŸ¯ {dataset_name}")
                print("-" * 50)
                print(f"L1 Loss:     {averages.get('l1', 'N/A'):.6f}")
                print(f"PSNR:        {averages.get('psnr', 'N/A'):.2f}")
                print(f"SSIM:        {averages.get('ssim', 'N/A'):.4f}")
                print(f"LPIPS:       {averages.get('lpips', 'N/A'):.4f}")
                print(f"FPS:         {averages.get('fps', 'N/A'):.1f}")
        
        # æ‰“å°å…¶ä»–å¯èƒ½çš„æ•°æ®é›†
        for dataset_name, averages in dataset_averages.items():
            if dataset_name not in dataset_order:
                print(f"\nğŸ¯ {dataset_name}")
                print("-" * 50)
                print(f"L1 Loss:     {averages.get('l1', 'N/A'):.6f}")
                print(f"PSNR:        {averages.get('psnr', 'N/A'):.2f}")
                print(f"SSIM:        {averages.get('ssim', 'N/A'):.4f}")
                print(f"LPIPS:       {averages.get('lpips', 'N/A'):.4f}")
                print(f"FPS:         {averages.get('fps', 'N/A'):.1f}")
        
        # æ‰“å°æ‰€æœ‰åœºæ™¯çš„è¯¦ç»†æ•°æ®
        print("\n" + "="*80)
        print("ğŸ“‹ æ‰€æœ‰åœºæ™¯è¯¦ç»†æ•°æ®")
        print("="*80)
        
        for scene, metrics in metrics_data.items():
            dataset_name = get_dataset_name(scene)
            print(f"\n{scene} ({dataset_name}):")
            print(f"  L1: {metrics.get('l1', 'N/A'):.6f}, PSNR: {metrics.get('psnr', 'N/A'):.2f}, "
                  f"SSIM: {metrics.get('ssim', 'N/A'):.4f}, LPIPS: {metrics.get('lpips', 'N/A'):.4f}, "
                  f"FPS: {metrics.get('fps', 'N/A'):.1f}")
    
    elif output_format == "csv":
        # ä¿å­˜ä¸ºCSVæ–‡ä»¶
        output_file = "dataset_averages.csv"
        
        # åˆ›å»ºæ•°æ®é›†å¹³å‡å€¼DataFrameï¼ŒæŒ‰æŒ‡å®šé¡ºåºæ’åˆ—
        dataset_order = [
            "MipNeRF360-Outdoor",
            "MipNeRF360-Indoor", 
            "MipNeRF360-All",
            "Tanks&Temples",
            "DeepBlending"
        ]
        
        # æŒ‰é¡ºåºåˆ›å»ºDataFrame
        ordered_data = {}
        for dataset_name in dataset_order:
            if dataset_name in dataset_averages:
                ordered_data[dataset_name] = dataset_averages[dataset_name]
        
        # æ·»åŠ å…¶ä»–æ•°æ®é›†
        for dataset_name, data in dataset_averages.items():
            if dataset_name not in dataset_order:
                ordered_data[dataset_name] = data
        
        avg_df = pd.DataFrame(ordered_data).T
        avg_df.index.name = "Dataset"
        
        # ä¿å­˜æ•°æ®é›†å¹³å‡å€¼
        avg_df.to_csv(output_file)
        print(f"ğŸ’¾ æ•°æ®é›†å¹³å‡å€¼å·²ä¿å­˜åˆ°: {output_file}")
        
        # åˆ›å»ºæ‰€æœ‰åœºæ™¯è¯¦ç»†æ•°æ®DataFrame
        detailed_df = pd.DataFrame(metrics_data).T
        detailed_df.index.name = "Scene"
        detailed_df['Dataset'] = [get_dataset_name(scene) for scene in detailed_df.index]
        
        # é‡æ–°æ’åˆ—åˆ—é¡ºåº
        cols = ['Dataset', 'l1', 'psnr', 'ssim', 'lpips', 'fps']
        detailed_df = detailed_df[cols]
        
        # ä¿å­˜è¯¦ç»†æ•°æ®
        detailed_file = "scene_details.csv"
        detailed_df.to_csv(detailed_file)
        print(f"ğŸ’¾ åœºæ™¯è¯¦ç»†æ•°æ®å·²ä¿å­˜åˆ°: {detailed_file}")

def main():
    parser = argparse.ArgumentParser(description="åˆ†æmetrics.csvæ–‡ä»¶ï¼Œè®¡ç®—æ•°æ®é›†å¹³å‡å€¼")
    parser.add_argument("--base_path", default="eval", help="åŸºç¡€è·¯å¾„")
    parser.add_argument("--iteration", type=int, default=30000, help="è¿­ä»£æ¬¡æ•°")
    parser.add_argument("--split", default="test", choices=["train", "test"], help="æ•°æ®é›†åˆ†å‰²")
    parser.add_argument("--output_format", default="table", choices=["table", "csv"], help="è¾“å‡ºæ ¼å¼")
    parser.add_argument("--scenes", nargs="+", help="æŒ‡å®šè¦åˆ†æçš„åœºæ™¯ï¼ˆå¯é€‰ï¼‰")
    
    args = parser.parse_args()
    
    print(f"ğŸ” åˆ†æè·¯å¾„: {args.base_path}")
    print(f"ğŸ”„ è¿­ä»£æ¬¡æ•°: {args.iteration}")
    print(f"ğŸ“Š æ•°æ®é›†åˆ†å‰²: {args.split}")
    
    # åŠ è½½æŒ‡æ ‡æ•°æ®
    metrics_data = load_metrics_from_path(args.base_path, args.iteration, args.split)
    
    if not metrics_data:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æŒ‡æ ‡æ•°æ®")
        return
    
    print(f"\nâœ… æˆåŠŸåŠ è½½ {len(metrics_data)} ä¸ªåœºæ™¯çš„æ•°æ®")
    
    # å¦‚æœæŒ‡å®šäº†ç‰¹å®šåœºæ™¯ï¼Œåªåˆ†æè¿™äº›åœºæ™¯
    if args.scenes:
        filtered_data = {}
        for scene in args.scenes:
            if scene in metrics_data:
                filtered_data[scene] = metrics_data[scene]
            else:
                print(f"âš ï¸  åœºæ™¯ {scene} ä¸åœ¨æ•°æ®ä¸­")
        metrics_data = filtered_data
    
    # è®¡ç®—æ•°æ®é›†å¹³å‡å€¼
    dataset_averages = calculate_dataset_averages(metrics_data)
    
    if not dataset_averages:
        print("âŒ æ— æ³•è®¡ç®—æ•°æ®é›†å¹³å‡å€¼")
        return
    
    # æ‰“å°ç»“æœ
    print_results(metrics_data, dataset_averages, args.output_format)
    
    # è®¡ç®—æ€»ä½“å¹³å‡å€¼
    all_metrics = list(metrics_data.values())
    if all_metrics:
        overall_df = pd.DataFrame(all_metrics)
        overall_averages = overall_df.mean().to_dict()
        
        print(f"\n" + "="*80)
        print("ğŸŒ æ€»ä½“å¹³å‡å€¼")
        print("="*80)
        print(f"L1 Loss:     {overall_averages.get('l1', 'N/A'):.6f}")
        print(f"PSNR:        {overall_averages.get('psnr', 'N/A'):.2f}")
        print(f"SSIM:        {overall_averages.get('ssim', 'N/A'):.4f}")
        print(f"LPIPS:       {overall_averages.get('lpips', 'N/A'):.4f}")
        print(f"FPS:         {overall_averages.get('fps', 'N/A'):.1f}")

if __name__ == "__main__":
    main() 